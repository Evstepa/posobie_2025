<div class="book__content">
  <br>
  <figure class="book__figure book__figure-text">
      <img class="book__img book__img-text" loading="lazy" src="./img/part-4/pic-4-2.jpg" alt="Хартли">
  </figure>

  <p class="book__descr book__title">
    Ральф Ви&#769;нтон Ла&#769;йон Ха&#769;ртли
  </p>
  <p class="book__descr book__title">
    (30.11.1888&nbsp;&mdash; 1.05.1970)
  </p>
  <p class="book__descr">
    Учёный-электронщик, специалист в&nbsp;области информатики, изобретатель Ральф Хартли родился в&nbsp;городке штата Невада. Учился в&nbsp;университете Юты, Оксфордском университете. Работал в&nbsp;научно-исследовательской лаборатории Western Electric. Там он&nbsp;принимал участие в&nbsp;создании радиоприёмника для трансатлантических тестов.
  </p>
  <p class="book__descr">
    Хартли в&nbsp;свой работе &laquo;Передача информации&raquo; (1928&nbsp;год) заложил основы информационной теории. Он&nbsp;ввёл понятие информации как случайной величины и&nbsp;первым попытался определить количество информации. Одной из&nbsp;самых важных формул этой работы является формула, которая сейчас носит имя автора&nbsp;&mdash; формула Хартли: <i>I</i>&nbsp;=&nbsp;log<sup>2</sup>&nbsp;<i>N</i>.
  </p>
  <p class="book__descr">
    Эту формулу используют, чтобы определить количество информации, которое содержится в&nbsp;сообщении. Здесь N&nbsp;&mdash; это количество символов в&nbsp;алфавите (мощность алфавита), <i>I</i>&nbsp;&mdash; количество информации в&nbsp;одном символе в&nbsp;битах.
  </p>
  <p class="book__descr">
    Хартли показал, что количество информации в&nbsp;сообщении зависит от&nbsp;мощности используемого алфавита и&nbsp;длины сообщения.
  </p>
  <p class="book__descr">
    Благодаря Хартли, в&nbsp;настоящее время количество информации измеряется в&nbsp;битах.
  </p>

</div>
